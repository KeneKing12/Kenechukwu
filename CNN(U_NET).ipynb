{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgIaL8Z4qGpZfPBUa8mDwG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KeneKing12/Kenechukwu/blob/main/CNN(U_NET).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import urllib.request\n",
        "\n",
        "# 1. Define URLs and Paths\n",
        "dataset_url = \"https://doi.org/10.5281/zenodo.5151941\"\n",
        "dataset_zip = \"MERGED_DATA.zip\"\n",
        "data_dir = \"plasticnet/data/train\"\n",
        "\n"
      ],
      "metadata": {
        "id": "FbO4nbl5k1bT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "VpoJGJF3bo4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(data_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "9-UwR7M8nnL_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(dataset_zip):\n",
        "    print(\"ðŸ“¥ Downloading dataset...\")\n",
        "    urllib.request.urlretrieve(dataset_url, dataset_zip)\n",
        "else:\n",
        "    print(\"âœ… Dataset already downloaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tuqf6c6KnrXs",
        "outputId": "39271a95-3b85-4422-f884-65186784fbf9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Dataset already downloaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Dataset Loader with Patching"
      ],
      "metadata": {
        "id": "Zavr40toSCCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MarineDebrisDataset(Dataset):\n",
        "    def __init__(self, img_paths, patch_size=128, stride=128):\n",
        "        self.data = []\n",
        "        for img_path in img_paths:\n",
        "            mask_path = img_path.replace('images', 'masks')\n",
        "\n",
        "            with rasterio.open(img_path) as src:\n",
        "                img = src.read().astype(np.float32) / 10000.0  # Normalize\n",
        "\n",
        "            with rasterio.open(mask_path) as src:\n",
        "                mask = src.read(1).astype(np.uint8)\n",
        "\n",
        "            # Extract patches\n",
        "            C, H, W = img.shape\n",
        "            for i in range(0, H - patch_size + 1, stride):\n",
        "                for j in range(0, W - patch_size + 1, stride):\n",
        "                    img_patch = img[:3, i:i+patch_size, j:j+patch_size]  # RGB only\n",
        "                    mask_patch = mask[i:i+patch_size, j:j+patch_size]\n",
        "                    if mask_patch.sum() > 0:  # optional: filter empty\n",
        "                        self.data.append((img_patch, (mask_patch > 0).astype(np.float32)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, mask = self.data[idx]\n",
        "        return torch.tensor(img), torch.tensor(mask).unsqueeze(0)  # [1, H, W]\n"
      ],
      "metadata": {
        "id": "rjDZxJIoR5Ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. U-Net Model (Simplified)"
      ],
      "metadata": {
        "id": "Q6fG6EeVSJNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.down1 = DoubleConv(3, 64)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.down2 = DoubleConv(64, 128)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.middle = DoubleConv(128, 256)\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
        "        self.conv1 = DoubleConv(256, 128)\n",
        "        self.up2 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.conv2 = DoubleConv(128, 64)\n",
        "\n",
        "        self.out = nn.Conv2d(64, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.down1(x)\n",
        "        x2 = self.down2(self.pool1(x1))\n",
        "        x3 = self.middle(self.pool2(x2))\n",
        "\n",
        "        x = self.up1(x3)\n",
        "        x = self.conv1(torch.cat([x, x2], dim=1))\n",
        "        x = self.up2(x)\n",
        "        x = self.conv2(torch.cat([x, x1], dim=1))\n",
        "\n",
        "        return torch.sigmoid(self.out(x))\n"
      ],
      "metadata": {
        "id": "owP50441R8vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data & Split"
      ],
      "metadata": {
        "id": "XIUpTA57SPVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_images = glob.glob('plasticnet/data/train/images/*.tif')\n",
        "dataset = MarineDebrisDataset(all_images)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=8)\n"
      ],
      "metadata": {
        "id": "iMtrb2YUR_Sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Setup"
      ],
      "metadata": {
        "id": "vYXeknM7SVbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = UNet().to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "pEwK5SHZSbDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train Loop"
      ],
      "metadata": {
        "id": "zRm5xlwkSdko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for images, masks in train_loader:\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "        preds = model(images)\n",
        "        loss = criterion(preds, masks)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Validation loss\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for images, masks in val_loader:\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            preds = model(images)\n",
        "            val_loss += criterion(preds, masks).item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "eve8wB5PShHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualize Prediction"
      ],
      "metadata": {
        "id": "Ktd4NhygSjj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_prediction():\n",
        "    model.eval()\n",
        "    image, mask = val_ds[0]\n",
        "    with torch.no_grad():\n",
        "        pred = model(image.unsqueeze(0).to(device)).squeeze().cpu().numpy()\n",
        "\n",
        "    plt.figure(figsize=(12,4))\n",
        "    plt.subplot(1,3,1); plt.imshow(np.moveaxis(image.numpy(), 0, -1)); plt.title(\"Image\")\n",
        "    plt.subplot(1,3,2); plt.imshow(mask.numpy()[0], cmap='gray'); plt.title(\"Ground Truth\")\n",
        "    plt.subplot(1,3,3); plt.imshow(pred > 0.5, cmap='gray'); plt.title(\"Prediction\")\n",
        "    plt.show()\n",
        "\n",
        "show_prediction()\n"
      ],
      "metadata": {
        "id": "gVQq-IsiSpLN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}