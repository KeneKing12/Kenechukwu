{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMP77mT6hXpgebLfkdtSq9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KeneKing12/Kenechukwu/blob/main/DETR_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class PositionalEncoding2D(nn.Module):\n",
        "    def __init__(self, d_model, height, width):\n",
        "        super().__init__()\n",
        "        if d_model % 4 != 0:\n",
        "            raise ValueError(\"d_model must be divisible by 4\")\n",
        "\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.d_model = d_model\n",
        "\n",
        "        pe = torch.zeros(d_model, height, width)\n",
        "        d_model = int(d_model / 2)\n",
        "        div_term = torch.exp(torch.arange(0., d_model, 2) * -(torch.log(torch.tensor(10000.0)) / d_model))\n",
        "        pos_w = torch.arange(0., width).unsqueeze(1)\n",
        "        pos_h = torch.arange(0., height).unsqueeze(1)\n",
        "\n",
        "        pe[0:d_model:2, :, :] = torch.sin(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1)\n",
        "        pe[1:d_model:2, :, :] = torch.cos(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1)\n",
        "        pe[d_model::2, :, :] = torch.sin(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
        "        pe[d_model+1::2, :, :] = torch.cos(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
        "\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :, :x.size(2), :x.size(3)]\n",
        "\n",
        "class DETROnlyModel(nn.Module):\n",
        "    def __init__(self, in_channels=11, d_model=256, nhead=8, num_layers=6, ff_dim=2048, height=16, width=16):\n",
        "        super().__init__()\n",
        "        self.input_proj = nn.Conv2d(in_channels, d_model, kernel_size=1)\n",
        "        self.pos_enc = PositionalEncoding2D(d_model, height, width)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=ff_dim, batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        self.output_proj = nn.Conv2d(d_model, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x)  # [B, d_model, H, W]\n",
        "        x = self.pos_enc(x)\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.flatten(2).permute(0, 2, 1)  # [B, HW, C]\n",
        "        x = self.transformer(x)\n",
        "        x = x.permute(0, 2, 1).reshape(B, C, H, W)\n",
        "\n",
        "        x = self.output_proj(x)\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "# Accuracy Function\n",
        "def compute_accuracy(preds, masks, threshold=0.5):\n",
        "    preds = (preds > threshold).float()\n",
        "    correct = (preds == masks).float()\n",
        "    return correct.sum() / correct.numel()\n",
        "\n",
        "# Example usage:\n",
        "# model = DETROnlyModel().to(device)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "# criterion = nn.BCELoss()\n",
        "# ... training loop similar to previous\n"
      ],
      "metadata": {
        "id": "hWDMdEGsj3Wv"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}