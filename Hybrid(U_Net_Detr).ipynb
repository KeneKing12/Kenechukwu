{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOR9c96q3y1EYKDv9oJYIk5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KeneKing12/Kenechukwu/blob/main/Hybrid(U_Net_Detr).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LvQCsB_bhgCV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "# --- DoubleConv block as used in U-Net ---\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "# --- Positional Encoding for 2D features ---\n",
        "class PositionalEncoding2D(nn.Module):\n",
        "    def __init__(self, d_model, height, width):\n",
        "        super().__init__()\n",
        "        if d_model % 4 != 0:\n",
        "            raise ValueError(\"d_model must be divisible by 4\")\n",
        "\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.d_model = d_model\n",
        "\n",
        "        pe = torch.zeros(d_model, height, width)\n",
        "        d_model = int(d_model / 2)\n",
        "        div_term = torch.exp(torch.arange(0., d_model, 2) * -(math.log(10000.0) / d_model))\n",
        "        pos_w = torch.arange(0., width).unsqueeze(1)\n",
        "        pos_h = torch.arange(0., height).unsqueeze(1)\n",
        "\n",
        "        pe[0:d_model:2, :, :] = torch.sin(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1)\n",
        "        pe[1:d_model:2, :, :] = torch.cos(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1)\n",
        "        pe[d_model::2, :, :] = torch.sin(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
        "        pe[d_model+1::2, :, :] = torch.cos(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
        "\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :, :x.size(2), :x.size(3)]\n",
        "\n",
        "# --- DETR-style Transformer Encoder ---\n",
        "class DETREncoder(nn.Module):\n",
        "    def __init__(self, d_model=256, nhead=8, num_layers=6, ff_dim=2048, height=16, width=16):\n",
        "        super().__init__()\n",
        "        self.pos_enc = PositionalEncoding2D(d_model, height, width)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=ff_dim, batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        x = self.pos_enc(x)\n",
        "        x = x.flatten(2).permute(0, 2, 1)\n",
        "        x = self.transformer(x)\n",
        "        x = x.permute(0, 2, 1).reshape(B, C, H, W)\n",
        "        return x\n",
        "\n",
        "# --- Hybrid U-Net with DETR Transformer Encoder ---\n",
        "class UNetWithDETREncoder(nn.Module):\n",
        "    def __init__(self, in_channels=11, out_channels=1, img_size=128):\n",
        "        super().__init__()\n",
        "        self.enc1 = DoubleConv(in_channels, 64)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.enc2 = DoubleConv(64, 128)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.enc3 = DoubleConv(128, 256)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.detr_encoder = DETREncoder(d_model=256, height=img_size // 8, width=img_size // 8)\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
        "        self.dec1 = DoubleConv(256, 128)\n",
        "        self.up2 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.dec2 = DoubleConv(128, 64)\n",
        "        self.out = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.enc1(x)\n",
        "        x2 = self.enc2(self.pool1(x1))\n",
        "        x3 = self.enc3(self.pool2(x2))\n",
        "\n",
        "        x_bottleneck = self.detr_encoder(self.pool3(x3))\n",
        "\n",
        "        x = self.up1(x_bottleneck)\n",
        "        x = self.dec1(torch.cat([x, x3], dim=1))\n",
        "        x = self.up2(x)\n",
        "        x = self.dec2(torch.cat([x, x2], dim=1))\n",
        "        return torch.sigmoid(self.out(x))\n",
        "\n",
        "# --- Accuracy computation ---\n",
        "def compute_accuracy(preds, masks, threshold=0.5):\n",
        "    preds = (preds > threshold).float()\n",
        "    correct = (preds == masks).float()\n",
        "    return correct.sum() / correct.numel()\n"
      ]
    }
  ]
}